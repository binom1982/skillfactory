# Группа: DST-48

Sergey Pinaev (binom1982@gmail.com)

# Проект №4. Компьютер говорит "Нет"

Ссылка на соревнование: [[SF-DST] Credit Scoring](https://www.kaggle.com/c/sf-dst-scoring)

<p align="center" width="100%">
    <img src="https://www.nfcc.org/wp-content/uploads/2020/09/bigstock-Credit-Score-Concept-Business-384487778-768x477.jpg"> 
</p>

## Задача

Представьте, что вы работаете стажером в отделении регионального банка. Вы все также делаете запросы к базам данных и строите отчеты. Вы поймали себя на мысли, что представляли работу дата-саентиста совсем иначе…

И вот сегодня, когда вы уже были на пороге отчаяния, ваш начальник пришел к вам с долгожданной новостью. Будем строить модель!

“Отлично,” – думаете вы, – “наконец-то смогу заняться настоящей работой!”

Задача: построить скоринг модель для вторичных клиентов банка, которая бы предсказывала вероятность дефолта клиента.

## Описание датасета

1. **client_id** - идентификатор клиента
2. **education** - уровень образования
3. **sex** - пол заёмщика
4. **age** - возраст заёмщика
5. **car** - флаг наличия автомобиля
6. **car_type** - флаг автомобиля-иномарки
7. **decline_app_cnt** - количество отказанных прошлых заявок
8. **good_work** -флаг наличия «хорошей» работы
9. **bki_request_cnt** - количество запросов в БКИ
10. **home_address** - категоризатор домашнего адреса
11. **work_address** - категоризатор рабочего адреса
12. **income	доход** - заёмщика
13. **foreign_passport** - наличие загранпаспорта
14. **sna** - связь с клиентом банка
15. **first_time** - давность информации о клиенте
16. **score_bki** - BKI очки
17. **region_rating** - райтинг региона
18. **app_date** - дата заявки
19. **default** - наличие дефолта

## Этапы работы над проектом

1. Первичная обработка данных;
2. Анализ распределения признаков. Замена пропусков;
3. EDA
4. Feature engineering;
5. Корреляционный анализ;
6. Отбор не коррелирующих переменных;
7. Анализ признаков и устранение тех, которые не влияют на предсказываемую величину;
8. Сравнительный анализ алгоритмов Классификации и подбор наилучших параметров.

## Выводы

В результате EDA и Feature engineering , было создано достаточно много новых признаков, некоторые из которых имеют очень высокую корреляцию Пирсона. Тем не менее удаление сильно коррелируемых признаков в ручную или с помощью алгоритма RFE немного но ухудшало метрику. Поэтому данный шаг считаю можно отсавить на будущее, когда уже модель пойдет в продакш и будет важна ее скорость.

Среди всех опробованных мною алгоритмов Классификации был выбран алгоритм - логистической регрессии (ЛР).

Самостоятельное устранение дисбаланса классов в ЛР не привело к улучшению метрики ROC_AUC (лучше установить параметр class_weight='balanced'). 

В результате проделанной работы (на дату **2021.04.24**) удалось занять **30** место (0.73911).

Задача очень интересная и практико-орентированная.
