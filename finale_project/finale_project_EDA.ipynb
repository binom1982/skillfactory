{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Группа: DST-48\n",
    "**Sergey Pinaev - binom1982@gmail.com**\n",
    "# Финальный проект \n",
    "Предсказание стоимости домов, основываясь на истории предложений.  \n",
    "\n",
    "Ссылка на соревнование: [[SF-DST] Car Price prediction](https://www.kaggle.com/c/sf-dst-car-price-prediction-part2)\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "<img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/080/2a6/5e7/0802a65e78ee2bd84388c0d1ebab98d5.png\" width=\"auto\"/>\n",
    "</p>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ко мне обратился представитель крупного агентства недвижимости со следующей проблемой:\n",
    "\n",
    "Мои риелторы тратят катастрофически много времени на сортировку объявлений и поиск выгодных предложений. Поэтому их скорость реакции, да и, сказать по правде, качество анализа не дотягивает до уровня конкурентов. А это сказывается на наших финансовых показателях. Твоя задача — разработать модель, которая бы позволила обойти конкурентов по скорости и качеству совершения сделок. Датасет прикладываю.\n",
    "\n",
    "**Цель**: разработать сервис, который будет предсказывать стоимость домов, основываясь на истории предложений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете 18 колонок\n",
    "\n",
    "Целевая переменная **target** - цена объекта недвижимости\n",
    "* **status** - статус объявления\n",
    "* **private pool** - наличие бассейна, вероятно дублируется столбцом **PrivatePool**\n",
    "* **propertyType** - тип объекта недвижимости\n",
    "* **street**- адрес\n",
    "* **baths** - количество ванных комнат\n",
    "* **homeFacts**- информация о доме. Этот столбец надо парсить\n",
    "* **fireplace** - наличие камина\n",
    "* **city** - город\n",
    "* **schools** - рейтинг и близость образовательных учреждений. Нужно парсить\n",
    "* **sqft** - площадь в квадратных футах\n",
    "* **zipcode** - почтовый индекс\n",
    "* **beds**- количество спальен (или количество кроватей) \n",
    "* **state** - штат\n",
    "* **stories** - вероятно, количество владельцев или продаж этого дома\n",
    "* **mls-id** - идентификационный номер в системе MLS. Вероятно, дополняется столбцом **MlsId**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import sys\n",
    "import PIL\n",
    "import cv2\n",
    "import re\n",
    "import json\n",
    "\n",
    "# import datetime, time\n",
    "from datetime import timedelta, datetime, date, time\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import RFE # Рекурсивное устранение признаков (RFE)\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error\n",
    "\n",
    "# # keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import albumentations\n",
    "\n",
    "# plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#увеличим дефолтный размер графиков\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "#графики в svg выглядят более четкими\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "# Подключаем форматирование Markdown\n",
    "from IPython.display import Markdown\n",
    "\n",
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)\n",
    "print('Tensorflow   :', tf.__version__)\n",
    "print('Keras        :', tf.keras.__version__)\n",
    "\n",
    "# Чтобы вычисления проходили на GPU необходимо чтобы tensorflow определил GPU.\n",
    "# Как это сделать практически без боли написано здесь https://artificialintelligence.so/forums/discussion/how-to-install-tensorflow/\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices()\n",
    "# Подключим видеокарту\n",
    "!nvidia-smi -L\n",
    "# !pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "isWorking = False # флаг для запуска кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred-y_true)/y_true))\n",
    "\n",
    "\n",
    "def get_other_values(series, percentile=90):\n",
    "    '''\n",
    "    Возвращает список значений ниже определенного порога, которые необходимо переменовать\n",
    "    '''\n",
    "    value_counts = series.value_counts()\n",
    "    # Найдем значения описывающие percentile всех значений\n",
    "    top_values = int(np.percentile(series.value_counts(dropna=False), percentile))\n",
    "    # Оставим только percentile значений\n",
    "    other = value_counts[value_counts < top_values].index\n",
    "#     display(other)\n",
    "    return other\n",
    "\n",
    "def get_emission_limits(data_series):\n",
    "    '''\n",
    "    Возвращает кортеж границ выбросов вычесленных на основе межвартильного размаха и 1 и 99 перцентиль.\n",
    "    При необходимости данные выходящие за нижнюю и верхнюю границу можно не удалять а присваивать им значение  1 и 99 перцентиля.\n",
    "    df.loc[df['column'] < min_emission_limits, 'column'] = perc01\n",
    "    df.loc[df['column'] > max_emission_limits, 'column'] = perc99\n",
    "    '''\n",
    "    perc25, perc75 = np.percentile(data_series,[25,75])\n",
    "    perc1, perc99 = np.percentile(data_series,[1,99])\n",
    "    # perc0, perc100 = np.percentile(data_series,[0,100])\n",
    "    # print(perc0, perc100) # Иногда выбросы меньше/больше min/max значений так что можно было бы доработать\n",
    "    \n",
    "    IQR = perc75 - perc25\n",
    "    min_emission_limits = perc25 - 1.5*IQR\n",
    "    max_emission_limits = perc75 + 1.5*IQR\n",
    "\n",
    "    '''Выводит распределение данных для каждого столбца в датасете'''\n",
    "    l = ['| P1 | Min emission | P25 | IQR | P75 | Max emission | P99 |',\n",
    "         '|-----|:-----:|----|-----|----|:-----:|-----|',\n",
    "        f'|{perc1}|{min_emission_limits}|{perc25}|{IQR}|{perc75}|{max_emission_limits}|{perc99}|']\n",
    "            \n",
    "    display(Markdown('\\n'.join(l)))\n",
    "    return perc1, min_emission_limits, max_emission_limits, perc99\n",
    "\n",
    "\n",
    "def get_boxplot(dataset, column, value, axes, kind=True):\n",
    "    '''Отображет boxplot'''\n",
    "    #fig, axes = plt.subplots(figsize=(10, 4))\n",
    "    \n",
    "    if kind:\n",
    "        sns.boxplot(x=column, y=value, data=dataset, ax=axes)\n",
    "    else:\n",
    "        sns.violinplot(x=column, y=value, data=dataset, ax=axes)\n",
    "    # plt.xticks(rotation=45)\n",
    "    # ax.set_title('Boxplot for ' + column)\n",
    "    # plt.show()\n",
    "    \n",
    "    \n",
    "def myround(x, prec=2, base=.05):\n",
    "    return round(base * round(float(x)/base), prec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"G:/Datasets/finale_project/data.csv/data.csv\"\n",
    "data = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.map(lambda x: x.replace(' ', '_').replace('-', '_'))\n",
    "display(data.head(4).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# список столбцов для удаления\n",
    "delete_col = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns \"mls_id\" and \"MlsId\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Начнем с удаления дубликатов в столбцах в названиях которых присутвует \"id\". \n",
    "print('Пропуски:', data.mls_id.isna().sum())\n",
    "print('Уникальных:', data.target.nunique())\n",
    "\n",
    "MlsId =  data.MlsId.value_counts(dropna=False)\n",
    "MlsId[MlsId >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data[data.MlsId == '58868465'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По самому частому 'MlsId' 6 записей по 3 в SAN ANTONIO и SEATTLE.\n",
    "Данные дублируют друг друга. Желательно удалить строки дубликатов.\n",
    "\n",
    "В них больше всего пропусков, соответственно, поэтому дополнение датасета данными из другой базы данных, \n",
    "например американской базы риелторов по этим id, представляется нецелесообразным, \n",
    "так как датасет будет дополнен неравномерно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Пока удалим столбец (по этому столбцу позже можно удалить дубли)\n",
    "delete_col.append(\"MlsId\")\n",
    "delete_col.append(\"mls_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Визуализируем пропуски:\n",
    "# fig, ax = plt.subplots(figsize=(15,10))\n",
    "# sns_heatmap=sns.heatmap(data.isnull(), yticklabels=False, cbar=False, cmap= 'coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"status\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Пропуски:', data.status.isna().sum())\n",
    "print('Уникальных:', data.status.nunique())\n",
    "\n",
    "data.status = data.status.str.upper()\n",
    "display(data.status.value_counts(dropna=False)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Больше 250.000 записей о продаже готовой недвижимости **ACTIVE**, **FOR SALE**,\n",
    "**NaN** значений около 40.000.\n",
    "\n",
    "Много записей о :\n",
    "* строящемся жилье **PENDING** \n",
    "* о выкупе у должников **FORECLOUSER**\n",
    "* отдельно указываются новостройки **NEW CONSTRUCTION**.\n",
    " \n",
    "Не очень понятна принципиальная разница между категориями 'ACTIVE' и 'FOR SALE'. Они по сути отражают одно и то же сотояние объекта недвижимоти - готовность объекта к продаже(активное объявление). \n",
    "\n",
    "Насчет заполнения пропусков. Раз они присутствуют в датасете - они должны быть активными и готовыми к продаже, как и абсолютное большинство других объявлений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_status(value):\n",
    "    if type(value)==str:\n",
    "        s = str(value)\n",
    "        if 'AUCTION' in s: return 'AUCTION'\n",
    "        if 'COMIN' in s or 'DILIGE' in s: return 'COMING'\n",
    "        if 'RENT' in s: return 'RENT'\n",
    "        if 'LEASE' in s: return 'RENT'\n",
    "        if 'PURCH' in s: return 'RENT'\n",
    "        if 'PEND' in s: return 'PENDING'\n",
    "        if 'FOREC' in s: return 'FORECLOSURE'\n",
    "        if 'NEW' in s: return 'NEW'\n",
    "        if 'CONTRACT' in s: return 'CONTRACT'\n",
    "        if 'CONTINGE' in s: return 'CONTINGENT'\n",
    "        if 'SOLD' in s or 'CLOSED' in s or 'ACCEPT' in s: return 'SOLD'\n",
    "        if 'ACTIV' in s: return 'ACTIVE'\n",
    "        if 'FOR SALE' in s: return 'FOR SALE'\n",
    "        if 'BACKUP' in s: return 'CONTRACT'\n",
    "        if 'BACK' in s or 'EXTEND' in s: return 'ACTIVE'\n",
    "        if 'CONTINUE' in s: return 'ACTIVE'\n",
    "        if s == 'C' or  s == 'CT': return 'CONTRACT'\n",
    "        if s == 'P': return 'PENDING'\n",
    "        if s == 'PS' or s == 'PF' or s == 'PI': return 'PENDING'\n",
    "       \n",
    "        else: return s\n",
    "    else:\n",
    "         # if s == 'nan' : return  \"NO_DATA\" # 'ACTIVE'\n",
    "        return \"NO_DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = data.status.map(parse_status)\n",
    "display(status.value_counts(dropna=False))\n",
    "data.status = status.astype(\"category\")\n",
    "# data.status.hist(figsize=(15,5), log=False, bins=50, xrot=90);\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видно, что для объявления о сдаче недвижимости в аренду, цена считается за месяц и в стоимости присутствует\n",
    "# приписка о помесячной оплате '/mo'. \n",
    "# Наш датасет должен содеражть данные о продаже жилья, а сдача жилья это уже для другой задачи. \n",
    "# Поэтому удалим удалим 424 записи со статусом 'RENT'.\n",
    "data[data.status == 'RENT']['target'][:8]\n",
    "\n",
    "# Удаляем записи\n",
    "data = data[data.status != 'RENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns \"private pool\" and \"PrivatePool\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# private_pool\n",
    "print('Пропуски:', data.private_pool.isna().sum())\n",
    "print('Уникальных:', data.private_pool.nunique())\n",
    "data.private_pool = data.private_pool.str.upper()\n",
    "\n",
    "display(data.private_pool.value_counts(dropna=False))\n",
    "data.private_pool.fillna(0, inplace=True)\n",
    "data.private_pool = data.private_pool.apply(lambda x: 1 if x == 'YES' else 0).astype('bool')\n",
    "display(data.private_pool.value_counts(dropna=False))\n",
    "\n",
    "# Данные о бассеинах не пересекаются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrivatePool\n",
    "print('Пропуски:', data.PrivatePool.isna().sum())\n",
    "print('Уникальных:', data.PrivatePool.nunique())\n",
    "data.PrivatePool = data.PrivatePool.str.upper()\n",
    "\n",
    "display(data.PrivatePool.value_counts(dropna=False))\n",
    "# data.PrivatePool = data.PrivatePool.apply(lambda x: x if type(x)!=str else x.lower())\n",
    "data.PrivatePool.fillna(0, inplace=True)\n",
    "data.PrivatePool = data.PrivatePool.apply(lambda x: 1 if x == 'YES' else 0).astype('bool')\n",
    "display(data.PrivatePool.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные из столбцов не пересекаются.\n",
    "Заполним NaN нулями, заменим 'Yes' и 'yes' на единицы и объединим эти два столбца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Я пока не могу понять почему эти данные не пересекаются, тут чтото не так!\n",
    "data['private_pool_union'] = False\n",
    "data.loc[data['private_pool'], 'private_pool_union'] = True\n",
    "data.loc[data['PrivatePool'], 'private_pool_union'] = True\n",
    "display(data.private_pool_union.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Пока удалим столбец (по этому столбцу позже можно удалить дубли)\n",
    "delete_col.append('private_pool')\n",
    "delete_col.append('PrivatePool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"propertyType\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Пропуски:', data.propertyType.isna().sum())\n",
    "print('Уникальных:', data.propertyType.nunique())\n",
    "data.propertyType = data.propertyType.str.upper()\n",
    "display(data.propertyType.value_counts(dropna=False))\n",
    "\n",
    "# propertyType = data.propertyType.apply(lambda x: x if type(x)!=str else x.replace(' ', '').replace('-', ''))\n",
    "# propertyType = propertyType.apply(lambda x: x if type(x)!=str else x.replace('singlefamilyhome', 'singlefamily'))\n",
    "\n",
    "# display(propertyType.value_counts(dropna=False))\n",
    "# Имеем 1280 описаний типа недвижимости. Надо разбить на разумное число категорий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_property_type(s):\n",
    "    s = str(s)\n",
    "    if 'SINGLE' in s or 'TRADITIONAL' in s: return 'SINGLE'\n",
    "    if 'CONDO' in s or 'FLAT' in s: return 'FLAT'\n",
    "    if 'TOWNH' in s: return 'TOWNHOUSE'\n",
    "    if 'COOP' in s or 'CO-OP' in s: return 'COOP'\n",
    "    if 'LAND' in s: return 'LAND'\n",
    "    if 'MULTI' in s: return 'MULTI'\n",
    "    if 'CONTEMPO' in s: return 'CONTEMPORARY'\n",
    "    if 'MOBI' in s or 'CARRI' in s: return 'MOBILE'\n",
    "    if 'TWO STOR' in s or '2 STOR' in s: return 'TWO-STORY'\n",
    "    if 'ONE STOR' in s or '1 STOR' in s: return 'ONE-STORY'\n",
    "    if 'STOR' in s in s: return 'MULTY-STORY'\n",
    "    if 'DETA' in s or 'DETA' in s: return 'DETACHED'\n",
    "    # if 'MID' in s or '5-9' in s  or '4' in s or '3' in s: return 'MID-RISE'\n",
    "    # if 'LOW' in s: return 'LOW-RISE'\n",
    "    # if 'HIGH' in s or 'UNIT' in s: return 'HIGH-RISE'\n",
    "    if 'RISE' in s or 'UNIT' in s or 'HIGH' in s: return 'FLAT'\n",
    "    if 'PENT' in s: return 'PENTHOUSE'\n",
    "    if 'RAN' in s: return 'RANCH'\n",
    "    if 'GARD' in s: return 'GARDEN HOME'\n",
    "    if 'CUST' in s or 'MANUF' in s or 'CRAFT' in s: return 'CUSTOM'\n",
    "    if 'ATTA' in s or 'PLEX' in s: return 'ATTACHED'\n",
    "    if 'FARM' in s: return 'FARM'\n",
    "    if 'LEVEL' in s: return 'SPLIT-LEVEL'\n",
    "    if 'OTHER' in s: return 'OTHER'\n",
    "    if 'COLO' in s: return 'COLONIAL'\n",
    "    if 'WARE' in s or 'COM' in s: return 'COMMERCICAL'\n",
    "    if 'COTT' in s or 'RESID' in s or 'COURT' in s: return 'COTTAGE'\n",
    "    if 'BOAT' in s: return 'BOATHOUSE'\n",
    "\n",
    "    if s == 'nan' or s == '': \n",
    "        return 'SINGLE'\n",
    "\n",
    "    else:\n",
    "         return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.propertyType = data.propertyType = data.propertyType.map(parse_property_type).astype('category')\n",
    "display(data.propertyType.value_counts(dropna=False))\n",
    "\n",
    "# data.propertyType.hist(figsize=(15,5), log=False, bins=200, xrot=90, orientation=\"vertical\");\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = (data.propertyType != 'FARM') #and (data.propertyType != 'COMMERCICAL') and (data.propertyType != 'BOATHOUSE')\n",
    "mask = ~data.propertyType.isin(['FARM', 'COMMERCICAL', 'BOATHOUSE'])\n",
    "data = data[mask]\n",
    "display(data.propertyType.value_counts(dropna=False))\n",
    "# propertyType.propertyType[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"street\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Пропуски:', data.street.isna().sum())\n",
    "print('Уникальных:', data.street.nunique())\n",
    "data.street = data.street.str.upper()\n",
    "display(data.street.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более 336 тысяч уникальных адресов. \n",
    "Возможно можно было бы извлечь из адресов геолокацию, для определения новых признаков таких как район, центр и тд. и посчитать для них среднюю или медианную цену. Но пока времени на это нет, если останется то попробую.\n",
    "\n",
    "Почти в каждом адресе есть аббревиатуры типа улицы, например 'BLVD' -бульвар, 'ROAD' - дорога и т.п. а также номер дома.\n",
    "\n",
    "Попробую из столбца 'street' сделать категориальный признак с типа улицы.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_street(s):\n",
    "    s = str(s)\n",
    "    if 'ADDRESS' in s: return 'NO_ADDRESS'\n",
    "    elif 'BLVD' in s or 'BOULEVARD' in s: return 'BOULEVARD'\n",
    "    elif 'WAY' in s: return 'HWAY'\n",
    "    elif 'CIR' in s: return 'CIRCLE'\n",
    "    elif 'CT' in s or 'COURT' in s: return 'COURT'\n",
    "    elif 'DR' in s or 'DRIVE' in s: return 'DRIVE'\n",
    "    elif 'RD' in s or 'ROAD' in s: return 'ROAD'\n",
    "    elif 'AVE' in s: return 'AVENUE'\n",
    "    elif 'ST' in s or 'STREET' in s: return 'STREET'\n",
    "    elif 'PL' in s: return 'PLACE'\n",
    "    elif 'LANE' in s: return 'LANE'\n",
    "    elif 'TR' in s or 'TRL' in s or 'TRAIL' in s: return 'TRAIL'\n",
    "    elif 'PARK' in s: return 'PARK'\n",
    "    else: return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['street_type'] = data.street.map(parse_street).astype('category')\n",
    "# TODO: Позже можно попробовать добавить новые признаки с средней/медианной ценой\n",
    "\n",
    "display(data.street_type.value_counts(dropna=False))\n",
    "data.street_type.hist(figsize=(12,5), log=False, bins=50, xrot=90);\n",
    "plt.tight_layout()\n",
    "\n",
    "# Удалим street\n",
    "delete_col.append('street')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,5))\n",
    "# ax = sns.boxplot(x=\"street_type\", y=\"target_log\", data=data);\n",
    "# ax.set_xticklabels(ax.get_xticklabels(),rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим признак наличия адреса\n",
    "data['has_address'] =  data.street_type.apply(lambda x: False if x == 'NO_ADDRESS' else True).astype(bool)\n",
    "display(data.has_address.value_counts(dropna=False))\n",
    "\n",
    "# Признак has_address практически не влияет на цену, но пока оставим\n",
    "# plt.figure(figsize=(12,5))\n",
    "# ax = sns.boxplot(x=\"has_address\", y=\"target_log\", data=data);\n",
    "# ax.set_xticklabels(ax.get_xticklabels(),rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_col.append('street')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"baths\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Пропуски:', data.baths.isna().sum())\n",
    "print('Уникальных:', data.baths.nunique())\n",
    "data.baths = data.baths.str.upper()\n",
    "display(data.baths.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У более чем 100000 записей нет информации о наличии ванной комнаты (TODO нужно подумать как быть)!\n",
    "Оказывается, что бывают ванны (https://www.realtor.com/advice/buy/what-is-a-half-bath/):\n",
    "* 1.0 полноценная - должна содержать четыре основных приспособления: унитаз, раковину, ванну и душ (или комбинацию душа и ванны).\n",
    "* 0.5 полуванна - имеет только два из четырех основных компонентов ванной комнаты, обычно унитаз и раковину\n",
    "* 0.75 трехчетвертная ванна - в ней не хватает одного из четырех перечисленных выше приспособлений. Чаще всего это будет ванна.\n",
    "* 0.25 четверть ванна - комната только с одним из четырех элементов, обычно это туалет\n",
    "\n",
    "Если в доме указано, что в нем три ванные комнаты и две полуванные, почему бы просто не сложить их все вместе и не сказать, что ванных комнат четыре? Это казалось бы логичным, но каждая ванная комната должна быть указана отдельно, потому что это дает покупателям жилья лучшее представление об особенностях дома и их возможностях, когда им просто нужно уйти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_baths(s):\n",
    "    s = str(s)\n",
    "    if s == '0': return 0.0\n",
    "    if s == '': return 1.0\n",
    "    if s == 'nan': return 1.0\n",
    "    if 'SQ. FT.' in s: return 1.0\n",
    "    if '-' in s or '—' in s or '~' in s: return 0.0\n",
    "    if 'SEMIMOD' in s: return 1.0\n",
    "    #if '/' in s: print(s)\n",
    "\n",
    "    s = s.replace(',', '.')\n",
    "    f = re.findall(r'\\d*\\.\\d+|\\d+', s)\n",
    "    try:\n",
    "        n = float(f[0])\n",
    "        if n >= 200:\n",
    "            n = n / 1000.\n",
    "        return n\n",
    "    except:\n",
    "        print(s)\n",
    "  \n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baths = data.baths.map(parse_baths)#.astype('category')\n",
    "# TODO: Нужно дополнительно обработать!\n",
    "\n",
    "display(baths.value_counts(dropna=False))\n",
    "data.baths = baths.round(1)\n",
    "display(data.baths.value_counts(dropna=False))\n",
    "# data.baths.hist(figsize=(12,5), log=False, bins=50, xrot=90);\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc1, min_emission_limits, max_emission_limits, perc99 = get_emission_limits(data.baths)\n",
    "\n",
    "data.baths.loc[data.baths < min_emission_limits] = 0 #int(perc1)\n",
    "data.baths.loc[data.baths > max_emission_limits] = int(perc99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменим выбросы минимальным значением 0 и максимальным 99 перцентилем\n",
    "perc1, min_emission_limits, max_emission_limits, perc99 = get_emission_limits(data.baths)\n",
    "display(data.baths.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.baths.hist(figsize=(12,5), log=False, bins=50, xrot=90);\n",
    "plt.tight_layout()\n",
    "# data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"homeFacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Пропуски:', data.homeFacts.isna().sum())\n",
    "print('Уникальных:', data.homeFacts.nunique())\n",
    "# display(data.homeFacts.value_counts(dropna=False))\n",
    "data.homeFacts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clen(str):\n",
    "  str = str.replace(\"''\", '0')\n",
    "  str = str.replace(\"'\", \"\")\n",
    "  str = str.replace(\"None\", '0')\n",
    "  str = str.replace(\"No Data\", '0')\n",
    "  str = str.replace(\"No Info\", '0')\n",
    "  str = str.replace(\"/sqft\", '')\n",
    "  str = str.replace(\"$\", '')\n",
    "  return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_home_facts(s):\n",
    "  res = []\n",
    "  s = s.split(\"{'atAGlanceFacts': [{'factValue': \")[1]\n",
    "  s = s.split(\", 'factLabel': 'Year built'}, {'factValue': \")\n",
    "  s[0] = clen(s[0])\n",
    "  # year = s[0]\n",
    "  res.append(s[0])\n",
    "  s = s[1].split(\", 'factLabel': 'Remodeled year'}, {'factValue': \")\n",
    "  s[0] = clen(s[0])\n",
    "  # remo = s[0]\n",
    "  res.append(s[0])\n",
    "  s = s[1].split(\", 'factLabel': 'Heating'}, {'factValue': \")\n",
    "  # heat = s[0]\n",
    "  res.append(s[0])\n",
    "  s = s[1].split(\", 'factLabel': 'Cooling'}, {'factValue': \")\n",
    "  # cool = s[0]\n",
    "  res.append(s[0])\n",
    "  s = s[1].split(\", 'factLabel': 'Parking'}, {'factValue': \")\n",
    "  s[0] = clen(s[0])\n",
    "  # park = s[0]\n",
    "  res.append(s[0])\n",
    "  s = s[1].split(\", 'factLabel': 'lotsize'}, {'factValue': \")\n",
    "  # size = s[0]\n",
    "  res.append(s[0])\n",
    "  s = s[1].split(\", 'factLabel': 'Price/sqft'}]}\")\n",
    "  s[0] = clen(s[0])\n",
    "  # price = s[0]\n",
    "  res.append(s[0])\n",
    "  return int(res[0]), int(res[1]), res[2], res[3], res[4], res[5], res[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeFacts = data.homeFacts.map(parse_home_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['hf_built_year', 'hf_remodeled_year' , 'hf_heating', 'hf_cooling', 'hf_parking', 'hf_lotsize' , 'hf_price_sqft' ]\n",
    "hf_data = pd.DataFrame.from_records(homeFacts, columns = new_columns)\n",
    "display(hf_data.head(5))\n",
    "# display(hf_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset analysis \"hf_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_data.hf_built_year\n",
    "print('Пропуски:', hf_data.hf_built_year.isna().sum())\n",
    "print('Уникальных:', hf_data.hf_built_year.nunique())\n",
    "display(hf_data.hf_built_year.value_counts(dropna=False))\n",
    "hf_data.hf_built_year.describe()\n",
    "# hf_data.hf_built_year.value_counts(dropna=False).hist(figsize=(12,5), log=False, bins=50, xrot=0);\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Почистим выбросы \n",
    "get_emission_limits(hf_data.hf_built_year)\n",
    "# data.enginePower.loc[data.enginePower < min_emission_limits] = int(perc1)\n",
    "# data.enginePower.loc[data.enginePower > max_emission_limits] = int(perc99)\n",
    "hf_data.hf_built_year[(hf_data.hf_built_year < 1700) | (hf_data.hf_built_year > 2025)].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_data.hf_built_year.replace(559990649990, 0, inplace=True)\n",
    "hf_data.hf_built_year.replace(1, 0, inplace=True)\n",
    "hf_data.hf_built_year.replace(1208, 0, inplace=True)\n",
    "hf_data.hf_built_year.replace(1057, 0, inplace=True)\n",
    "hf_data.hf_built_year.replace(1060, 0, inplace=True)\n",
    "hf_data.hf_built_year.replace(1019, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_remodeled_year\n",
    "print('Пропуски:', hf_data.hf_remodeled_year.isna().sum())\n",
    "print('Уникальных:', hf_data.hf_remodeled_year.nunique())\n",
    "display(hf_data.hf_remodeled_year.value_counts(dropna=False))\n",
    "hf_data.hf_remodeled_year.describe()\n",
    "# hf_data.hf_remodeled_year.value_counts(dropna=False).hist(figsize=(12,5), log=False, bins=50, xrot=0);\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Почистим выбросы, год реконструкии должен быть больше или равен году реконструкции и меньше 2022 года, если 0 то не ремонтировался\n",
    "get_emission_limits(hf_data.hf_remodeled_year)\n",
    "\n",
    "hf_data[((hf_data.hf_remodeled_year < hf_data.hf_built_year) | (hf_data.hf_remodeled_year > 2025)) & hf_data.hf_remodeled_year != 0].head(5) #.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# У 1481 дома, реконструкция проводилась раньше постройки, что невозможно! Присвоим таким значениям 0\n",
    "hf_data.loc[((hf_data.hf_remodeled_year < hf_data.hf_built_year) | (hf_data.hf_remodeled_year > 2025)) & hf_data.hf_remodeled_year != 0] = 0\n",
    "hf_data[((hf_data.hf_remodeled_year < hf_data.hf_built_year) | (hf_data.hf_remodeled_year > 2025)) & hf_data.hf_remodeled_year != 0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим признак реконструкции и признак числа лет прошедших после постройки\n",
    "hf_data['hf_has_remodeled'] = hf_data.hf_built_year != 0\n",
    "display(hf_data.hf_has_remodeled.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим признак: количество лет между строительством и модернизацией, если ремонта небыло, то поставим -1\n",
    "hf_data['hf_years_before_remodeled'] = (hf_data.hf_remodeled_year - hf_data.hf_built_year)\n",
    "hf_data.hf_years_before_remodeled = hf_data.hf_years_before_remodeled.apply(lambda p: p if p >= 0 else -1 )\n",
    "display(hf_data.hf_years_before_remodeled.value_counts(dropna=False))\n",
    "# TODO Признак не идеальный у него много выбросов, нужно подумать...\n",
    "get_emission_limits(hf_data.hf_years_before_remodeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_heating\n",
    "print('Пропуски:', hf_data.hf_heating.isna().sum())\n",
    "print('Уникальных:', hf_data.hf_heating.nunique())\n",
    "hf_data.hf_heating = hf_data.hf_heating.str.upper()\n",
    "display(hf_data.hf_heating.value_counts(dropna=False)[:20])\n",
    "# hf_data.hf_heating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_heat(s):\n",
    "    s = str(s)\n",
    "    if len(s) == 0 or s == '' or s ==\"''\" or s == ' ' or 'NO DATA' in s: return 'NO_DATA'\n",
    "    if 'AIR' in s or 'HEAT PUMP' in s: return 'AIR'\n",
    "    if 'GAS' in s or 'PROPANE' in s: return 'GAS'\n",
    "    if 'ELECTRIC' in s: return 'ELECTRIC'\n",
    "    if 'NONE' in s or 'NO' in s: return 'NONE'\n",
    "    if 'CENTRAL' in s: return 'CENTRAL'\n",
    "    else: return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_data.hf_heating = hf_data.hf_heating.map(parse_heat).astype('category')\n",
    "display(hf_data.hf_heating.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_cooling\n",
    "print('Пропуски:', hf_data.hf_cooling.isna().sum())\n",
    "print('Уникальных:', hf_data.hf_cooling.nunique())\n",
    "hf_data.hf_cooling = hf_data.hf_cooling.str.upper()\n",
    "display(hf_data.hf_cooling.value_counts(dropna=False)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cooling(s):\n",
    "    s = str(s)\n",
    "    if len(s) == 0 or s == '' or s ==\"''\" or s == ' ' or 'NO DATA' in s: return 'NO_DATA'\n",
    "    #if 'EVAPORATIVE' in s: return 'EVAPORATIVE'\n",
    "    if 'CENTRAL' in s: return 'CENTRAL'\n",
    "    if 'NONE' in s or 'NO' in s: return 'NONE'\n",
    "    else: return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_data.hf_cooling = hf_data.hf_cooling.map(parse_cooling).astype('category')\n",
    "display(hf_data.hf_cooling.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_parking\n",
    "print('Пропуски:', hf_data.hf_parking.isna().sum())\n",
    "print('Уникальных:', hf_data.hf_parking.nunique())\n",
    "hf_data.hf_parking = hf_data.hf_parking.str.upper()\n",
    "display(hf_data.hf_parking.value_counts(dropna=False)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_parking(s):\n",
    "    s = str(s)\n",
    "    #if len(s) == 0 or s == '' or s ==\"''\" or s == ' ' or 'NO DATA' in s: return 'NO_DATA'\n",
    "    if '1' in s or \"ONE\" in s or 'SING' in s: return 'ONE'\n",
    "    elif '2' in s or \"TWO\" in s or \"DOUB\" in s: return 'TWO'\n",
    "    elif '3' in s: return 'THREE'\n",
    "    elif 'ATTACHED' in s: return 'ATTACHED'\n",
    "    elif 'DETACHED' in s: return 'DETACHED'\n",
    "    elif 'OFF' in s: return 'OFF_STREET'\n",
    "    elif 'ON' in s: return 'ON_STREET'\n",
    "    elif 'CAR' in s: return 'CARPORT'\n",
    "    elif '4' in s or '5' in s or '6' in s or '7' in s or '8' in s or '9' in s: return 'FOUR_OR_MORE'\n",
    "    elif 'NONE' in s or 'NO' in s or s == '0': return 'NONE'\n",
    "    else: return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_data.hf_parking = hf_data.hf_parking.map(parse_parking).astype('category')\n",
    "display(hf_data.hf_parking.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_lotsize\n",
    "print('Пропуски:', hf_data.hf_lotsize.isna().sum())\n",
    "print('Уникальных:', hf_data.hf_lotsize.nunique())\n",
    "hf_data.hf_lotsize = hf_data.hf_lotsize.str.upper()\n",
    "display(hf_data.hf_lotsize.value_counts(dropna=False)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбец содержит данные о пощади. Возможно, площадь участка.\n",
    "Около 96000 значений типа NONE, ' ', '—', 'NO DATA', '-- SQFT LOT'\n",
    "Есть измерения в квадратных футах и акрах.\n",
    "Переведем акры в квадратные футы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lotsize(s):\n",
    "    s = str(s)\n",
    "    if len(s) == 0 or s == ' ':  return '', 0.0\n",
    "    elif 'nan' in s: return '', 0.0\n",
    "    elif s == '' or 'NO' in s or '—' in s or '-' in s: return '', 0.0\n",
    " \n",
    "    elif ' SQ' in s: \n",
    "        s = s.replace(',', '')\n",
    "        s = s.replace('.', '')\n",
    "        s = s.replace('\"', '')\n",
    "        s = s.replace(\"'\", '')\n",
    "        s = s.split(' ')\n",
    "        try:\n",
    "            return 'SQ', float(s[0])\n",
    "        except:\n",
    "            # print('EX_SQ', s)\n",
    "            return 'SQ_EX', 0.0\n",
    "\n",
    "    elif ' AC' in s: \n",
    "        s = s.replace(',', '')\n",
    "        s = s.replace('.', '')\n",
    "        s = s.replace('\"', '')\n",
    "        s = s.replace(\"'\", '')\n",
    "        s = s.split(' ')\n",
    "        try:\n",
    "            return 'AC', float(s[0])*43560 # переводим в квадратные футы\n",
    "        except:\n",
    "            # print ('EX_AC', s)\n",
    "            return 'AC_EX', 0.0\n",
    "    \n",
    "    else: \n",
    "        # print ('EX', s)\n",
    "        return 'EX', s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_lotsize = hf_data.hf_lotsize.map(parse_lotsize).astype('category')\n",
    "display(hf_lotsize.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, values = zip(*hf_lotsize)\n",
    "a = pd.Series(values, idx)\n",
    "display(a.index.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные гразные. Площадь есть в акрах, есть в квадратных футах, а есть без указания единиц измерения. Такой столбец очень, проблематично чистить. \n",
    "Тем более он будет сильно коллерировать с столбцом \"sqft\" в основном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим hf_lotsize\n",
    "delete_col.append('hf_lotsize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_price_sqft\n",
    "print('Пропуски:', hf_data.hf_price_sqft.isna().sum())\n",
    "print('Уникальных:', hf_data.hf_price_sqft.nunique())\n",
    "hf_data.hf_price_sqft = hf_data.hf_price_sqft.str.upper()\n",
    "display(hf_data.hf_price_sqft.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом столбце представлена площадь за квадратный метр. \n",
    "65627 нулевых значений. Можно попробовать заменить их, например, медианными значениями по городу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Пока удалим но нужно подумать\n",
    "# Удалим hf_lotsize\n",
    "delete_col.append('hf_price_sqft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.head(2))\n",
    "display(hf_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.info())\n",
    "display(hf_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединим с итоговым датасетом\n",
    "delete_col.append('homeFacts')\n",
    "data_new = data.merge(hf_data, left_index=True, right_index=True)\n",
    "data_new.head(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"fireplace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fireplace\n",
    "print('Пропуски:', data_new.fireplace.isna().sum())\n",
    "print('Уникальных:', data_new.fireplace.nunique())\n",
    "data_new.fireplace = data_new.fireplace.str.lower()\n",
    "display(data_new.fireplace.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clen_fireplace(string):\n",
    "  if type(string)!=str: return 0\n",
    "  if(len(str(string))==0): return 0\n",
    "  res = 0\n",
    "  res = re.findall(r'\\d+', str(string)) \n",
    "  if(res): return int(res[0])\n",
    "  if('yes' in string): return 1\n",
    "  if('not applicable' in string): return 0\n",
    "  if('storage' in string): return 0\n",
    "  if('one' in string): return 1\n",
    "  if('two' in string): return 2\n",
    "  if('three' in string): return 3\n",
    "  if('four' in string): return 4\n",
    "  if('five' in string): return 5\n",
    "  if('six' in string): return 6\n",
    "  if('seven' in string): return 7\n",
    "  if('eight' in string): return 8\n",
    "  if('nine' in string): return 9\n",
    "  if('ten' in string): return 0\n",
    "  if('eleven' in string): return 11\n",
    "  if('twelve' in string): return 12\n",
    "  return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireplace = data_new.fireplace.map(clen_fireplace) #.astype('category')\n",
    "display(fireplace.value_counts(dropna=False))\n",
    "# data_new.fireplace = fireplace\n",
    "\n",
    "get_emission_limits(fireplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireplace.loc[fireplace > 12] = 12\n",
    "display(fireplace.value_counts(dropna=False))\n",
    "data_new.fireplace = fireplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"сity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city\n",
    "print('Пропуски:', data_new.city.isna().sum())\n",
    "print('Уникальных:', data_new.city.nunique())\n",
    "data_new.city = data_new.city.str.upper()\n",
    "display(data_new.city.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим 34 записи с пропусками городов.\n",
    "Есть идея, подключить внешние данные с рейтингами городов по нескольким параметрам:\n",
    "* криминальный рейтинг города\n",
    "* экологический рейтинго города\n",
    "* деловой рейтинг города\n",
    "* образовательный рейтинг города\n",
    "* общий рейтинг города у релтеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.dropna(subset=['city'], inplace=True)\n",
    "data_new.city = data_new.city.astype('category')\n",
    "print('Пропуски:', data_new.city.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"schools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Пропуски:', data_new.schools.isna().sum())\n",
    "print('Уникальных:', data_new.schools.nunique())\n",
    "display(data_new.schools[0])\n",
    "# data_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_school(s):\n",
    "   s = s[1:-1]\n",
    "   s = s.replace(\"'\", '\"')\n",
    "   s = s.split(', \"name\"')\n",
    "  #  pprint(s)\n",
    "  #  pprint(s[0])\n",
    "   s = s[0] + \"}\"\n",
    "   s = s.replace(' None, ', ' \"None\", ')\n",
    "\n",
    "   #print(ind, s)\n",
    "   d = json.loads(s)\n",
    "   dictance = []\n",
    "   grades = []\n",
    "   rating = []\n",
    "   grades = d['data']['Grades']\n",
    "   for i in d['data']['Distance']:\n",
    "     i = float(i.replace('mi', ''))\n",
    "     dictance.append(i)\n",
    "   for i in d['rating']:\n",
    "     if '/'in i:\n",
    "       i = i.split('/')[0]\n",
    "     rating.append(i)\n",
    "\n",
    "   return dictance, grades, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = data_new.schools.map(parse_school) #.astype('category')\n",
    "# schools.columns = ['sk_dist', 'sk_grades', 'sk_rating']\n",
    "schools[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data = pd.DataFrame.from_records(schools, columns = ['sk_dist', 'sk_grades', 'sk_rating'])\n",
    "display(school_data.head(5))\n",
    "display(school_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def school_distance_min_and_meam(dist):\n",
    "   dist = list(dist)\n",
    "   if len(dist) == 0:\n",
    "     min = mean = 0\n",
    "   else:\n",
    "     d = np.array(dist)\n",
    "     min = d.min()\n",
    "     mean = d.mean()\n",
    "   \n",
    "   return np.round(min, 1), np.round(mean, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим признак минимального и среднего расстояния до школы\n",
    "x = school_data.sk_dist.map(school_distance_min_and_meam) #.astype('category')\n",
    "new_features = pd.DataFrame.from_records(x, columns = ['sk_distance_min', 'sk_distance_mean'])\n",
    "\n",
    "school_data  = school_data.merge(new_features, left_index=True, right_index=True)\n",
    "school_data.head(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def school_rating(r):\n",
    "   a = []\n",
    "   if len(r) == 0:\n",
    "     min = max = mean = 0\n",
    "   else:\n",
    "     for i in r:\n",
    "       #print(type(i))\n",
    "       if is_number(i):\n",
    "         a.append(int(i))\n",
    "   if len(a) == 0:\n",
    "     min = max = mean = 0\n",
    "   else:  \n",
    "     d = np.array(a)\n",
    "     min = d.min()\n",
    "     max = d.max()\n",
    "     mean = d.mean()\n",
    "   \n",
    "   return np.round(min,1), np.round(max, 1), np.round(mean, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = school_data.sk_rating.map(school_rating)\n",
    "new_features = pd.DataFrame.from_records(x, columns = ['sk_rating_min', 'sk_rating_max', 'sk_rating_mean'])\n",
    "\n",
    "school_data  = school_data.merge(new_features, left_index=True, right_index=True)\n",
    "school_data.head(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_replace(s):\n",
    "  g = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "  s = s.replace('PK', '0')\n",
    "  s = s.replace('Pk', '0')\n",
    "  s = s.replace('K', '0')\n",
    "  s = s.replace('Preschool to ', '0-')\n",
    "  s = s.replace('N/A', '999')\n",
    "  s = s.replace('NA', '999')\n",
    "  s = s.replace('None', '999')\n",
    "  s = s.replace(' - ', '-')\n",
    "  s = s.replace(' – ', '-')\n",
    "  s = s.replace('–', '-')\n",
    "  s = s.replace(' to ', '-')\n",
    "  s = s.split(', ')\n",
    "  \n",
    "  if s[0] == '999':\n",
    "    return g\n",
    "  \n",
    "  a = []\n",
    "  a = s[0].split('-')\n",
    "  if len(a) == 2:\n",
    "    for i in range(int(a[0]), int(a[1])+1):\n",
    "      g[i] = g[i] + 1\n",
    "  else:\n",
    "    g[int(a[0])] = g[int(a[0])] + 1\n",
    "\n",
    "  if len(s) == 2:\n",
    "    b = []\n",
    "    b = s[1].split('-')\n",
    "    if len(b) == 2:\n",
    "      for i in range(int(b[0]), int(b[1])+1):\n",
    "        g[i] = g[i] + 1\n",
    "      else:\n",
    "        g[int(b[0])] = g[int(b[0])] + 1\n",
    "\n",
    "  return g\n",
    "\n",
    "def sk_g(l):\n",
    "   g = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "   if type(l) != list:\n",
    "     return g\n",
    "\n",
    "   if len(l) == 0:\n",
    "     return g\n",
    "\n",
    "   for i in l:\n",
    "     g = g + grade_replace(i)\n",
    "\n",
    "   return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = school_data.sk_grades.map(sk_g)\n",
    "new_features = pd.DataFrame.from_records(x, columns = ['sk_gr_pk','sk_gr_01', 'sk_gr_02', 'sk_gr_03', 'sk_gr_04', 'sk_gr_05', 'sk_gr_06', 'sk_gr_07', 'sk_gr_08', 'sk_gr_09', 'sk_gr_10', 'sk_gr_11', 'sk_gr_12'])\n",
    "\n",
    "school_data  = school_data.merge(new_features, left_index=True, right_index=True)\n",
    "school_data.head(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате получили следующие столбцы:\n",
    "* **sk_dist_min** - минимальное расстояние до школы\n",
    "* **sk_dist_mean** - среднее расстояние до школы\n",
    "* **sk_rating_min** - минимальный рейтинг школы\n",
    "* **sk_rating_max** - максимальный рейтинг школы\n",
    "* **sk_rating_mean** - средний рейтинг школ в окрестностях\n",
    "* **sk_gp_pk** - количество детских садов (дощкольных образовательных учреждений) в окресностях\n",
    "* **sk_gr_01** по **sk_gr_12** - количество школ с соответсвующими классами обучения (с 1 по 12) в окрестностях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data.drop(['sk_dist', 'sk_grades', 'sk_rating'], axis=1, inplace=True)\n",
    "school_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_new.info())\n",
    "display(school_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим признак schools и объедим с новым датасетом\n",
    "delete_col.append('schools')\n",
    "data_new  = data_new.merge(school_data, left_index=True, right_index=True)\n",
    "data_new.head(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"sqft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Пропуски:', data_new.sqft.isna().sum())\n",
    "print('Уникальных:', data_new.sqft.nunique())\n",
    "data_new.sqft = data_new.sqft.str.upper()\n",
    "display(data_new.sqft.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqft = data_new.sqft.replace(r'\\D+',  np.nan,  regex=True)\n",
    "display(sqft.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqft.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqft.\n",
    "def clen_nan(string):\n",
    "  if type(string)!=str: \n",
    "      print(string)\n",
    "\n",
    "# sqft.map(clen_nan)\n",
    "# TODO проблемный признак пока оставим\n",
    "\n",
    "# Удалим\n",
    "delete_col.append('sqft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"zipcode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Пропуски:', data_new.zipcode.isna().sum())\n",
    "print('Уникальных:', data_new.zipcode.nunique())\n",
    "data_new.zipcode = data_new.zipcode.str.upper()\n",
    "display(data_new.zipcode.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTO Пока удалим\n",
    "delete_col.append('zipcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"beds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Пропуски:', data_new.beds.isna().sum())\n",
    "print('Уникальных:', data_new.beds.nunique())\n",
    "data_new.beds = data_new.beds.str.upper()\n",
    "display(data_new.beds.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_beds(s):\n",
    "    s = str(s)\n",
    "    if len(s) == 0 or s == ' ':  return 0, 0\n",
    "    if 'nan' in s: return 0, 0\n",
    "    if '--' in s: return 0, 0\n",
    "    if 'BAT' in s: return 1, 0\n",
    "\n",
    "    if ' BED' in s or ' BD' in s: \n",
    "        s = s.split(' ')\n",
    "        try:\n",
    "            return float(s[0]), 0\n",
    "        except:\n",
    "            return 1, 0\n",
    "\n",
    "    if ' SQ' in s: \n",
    "        s = s.split(' ')\n",
    "        try:\n",
    "            return 1, float(s[0])\n",
    "        except:\n",
    "            # print('EX_SQ', s)\n",
    "            return 1, 0\n",
    "\n",
    "    if ' AC' in s: \n",
    "        s = s.split(' ')\n",
    "        try:\n",
    "            return 1, float(s[0])*43560\n",
    "        except:\n",
    "            # print ('EX_AC', s)\n",
    "            return 1, 0\n",
    "    \n",
    "    try:\n",
    "        n = s.split(' ')\n",
    "        try:\n",
    "            #print (\"EX1\", s)\n",
    "            return float(n[0]), 0\n",
    "        except:\n",
    "            # print ('EX2', s)\n",
    "            return 1, 0\n",
    "    except:\n",
    "         return 1, 0\n",
    "    #     try:\n",
    "    #         print (\"EX3\", s)\n",
    "    #         return float(s), 0\n",
    "    #     except:\n",
    "    #         print ('EX4', s)\n",
    "    #         return 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beds = data_new.beds.map(parse_beds) #.astype('category')\n",
    "display(beds.value_counts(dropna=False))\n",
    "\n",
    "data_beds = pd.DataFrame(beds.tolist(), columns=['beds_num', 'beds_area'])\n",
    "display(data_beds.head(5))\n",
    "data_beds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_new.info())\n",
    "display(data_beds.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_beds.astype(int).value_counts(dropna=False))\n",
    "data_beds = data_beds.astype(int)\n",
    "print('Пропуски:', data_beds.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим признак beds\n",
    "delete_col.append('beds')\n",
    "data_new = data_new.join(data_beds)\n",
    "display(data_new.head(2))\n",
    "data_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Пропуски:', data_new.state.isna().sum())\n",
    "print('Уникальных:', data_new.state.nunique())\n",
    "data_new.state = data_new.state.str.upper()\n",
    "display(data_new.state.value_counts(dropna=False)[:25])\n",
    "# Всего 38 уникальных штата.\n",
    "# Большинство обявлений о продаже в Филадельфии (FL) и Техасе (TX).\n",
    "data_new.state = data_new.state.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"stories\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Пропуски:', data_new.stories.isna().sum())\n",
    "print('Уникальных:', data_new.stories.nunique())\n",
    "data_new.stories = data_new.stories.str.lower()\n",
    "display(data_new.stories.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_stories(string):\n",
    "  if type(string)!=str: return 0 # Пропуски 150103\n",
    "  if(len(str(string))==0): return 0\n",
    "  string.replace(',', '.')\n",
    "  res = []\n",
    "  res = re.findall(r'\\d+\\.\\d+', str(string)) \n",
    "  if(res): return float(res[0])\n",
    "  res = re.findall(r'\\d+', str(string)) \n",
    "  if(res): return float(res[0])\n",
    "  if('yes' in string): return 1\n",
    "  if('not applicable' in string): return 0\n",
    "  if('storage' in string): return 0\n",
    "  if('one' in string): return 1\n",
    "  if('two' in string): return 2\n",
    "  if('three' in string): return 3\n",
    "  if('four' in string): return 4\n",
    "  if('five' in string): return 5\n",
    "  if('six' in string): return 6\n",
    "  if('seven' in string): return 7\n",
    "  if('eight' in string): return 8\n",
    "  if('nine' in string): return 9\n",
    "  if('ten' in string): return 0\n",
    "  if('eleven' in string): return 11\n",
    "  if('twelve' in string): return 12\n",
    "  return 0 # если не распарсили то пусть будет 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = data_new.stories.map(parse_stories) #.astype('category')\n",
    "display(stories.value_counts(dropna=False))\n",
    "perc1, min_emission_limits, max_emission_limits, perc99 = get_emission_limits(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_new.stories.loc[data_new.stories < min_emission_limits] = 0 #int(perc1)\n",
    "stories.loc[stories > max_emission_limits] = int(perc99)\n",
    "display(stories.value_counts(dropna=False))\n",
    "#data_new.stories = stories.astype(int)\n",
    "data_new.stories = stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Пропуски:', data_new.target.isna().sum())\n",
    "print('Уникальных:', data_new.target.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим 2476 пустых значения\n",
    "data_new.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "print('Пропуски:', data_new.target.isna().sum())\n",
    "print('Уникальных:', data_new.target.nunique())\n",
    "\n",
    "data_new.target = data_new.target.str.upper()\n",
    "display(data_new.target.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_new.target.apply(lambda x: x if type(x)!=str else x\n",
    "                                .replace('$', '')\n",
    "                                .replace('+', '')\n",
    "                                .replace(',', '')\n",
    "                                ).astype(int)\n",
    "\n",
    "# display(data.target.value_counts(dropna=False))\n",
    "data_new.target = target\n",
    "# data_new['target_log'] = np.log(data_new.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_new.target.plot()\n",
    "data_new.target.plot(figsize=(12,5));\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты EDA\n",
    "* Обработал данные, создал новые признаки, прологарифмировал целевую переменную\n",
    "* Из-за большого количества пропусков в данных приходилось менять их на значения \"NO_DATA\" \n",
    "* Если останется время, можно получить дополнительную информацию о городах из внешних источников."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_new.head(3))\n",
    "data_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  data_new.drop(delete_col, axis=1)\n",
    "dataset.status = dataset.status.astype('category')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Код ML вынесем в отдельный блокнот"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83612696a71488aa3c58c647d24dc19ba152fc7225cd05d452bdd4b0a131fc0b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tensorflow_25': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
